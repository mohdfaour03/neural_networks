{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3gTyckJDLQEzlxzygXYy3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohdfaour03/neural_networks/blob/main/Pr3_part4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukWUnrGU2reC",
        "outputId": "d3382382-96ba-4a4b-8f63-eceaca375ba4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting NN.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile NN.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "##Implementing the neural network\n",
        "class NN(object):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        #Define the wieght matrices and the bias\n",
        "        self.W1 = np.random.rand(self.input_size, self.hidden_size)\n",
        "        self.b1 = np.zeros((1, self.hidden_size))\n",
        "        self.W2 = np.random.rand(self.hidden_size, self.hidden_size)\n",
        "        self.b2 = np.zeros((1, self.hidden_size))\n",
        "        self.W3 = np.random.rand(self.hidden_size, self.output_size)\n",
        "        self.b3 = np.zeros((1, self.output_size))\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        self.z3 = np.dot(self.a2, self.W3) + self.b3\n",
        "        self.a3 = self.sigmoid(self.z3)\n",
        "        self.y_hat = self.a3\n",
        "        return self.y_hat ### Returning the prediction\n",
        "\n",
        "    def compute_loss(self, y_true, y_pred):\n",
        "        return np.mean((y_true - y_pred)**2)\n",
        "\n",
        "    def backward(self, X, y_true, y_pred):\n",
        "        m = y_true.shape[0]  # Number of samples\n",
        "        print(\"y_true shape:\", y_true.shape)\n",
        "        print(\"y_pred shape:\", y_pred.shape)\n",
        "\n",
        "        y_true = y_true.reshape(-1, 1)  # Ensure y_true is of shape (m, 1\n",
        "        # Output Layer.. Compute the derivative of the loss w.r.t y_pred\n",
        "        dL_dy_pred = 2 * (y_pred - y_true) / m  # (m, o)\n",
        "\n",
        "        # Compute dz3\n",
        "        dz3 = dL_dy_pred * self.sigmoid_derivative(y_pred)  # (m, o)\n",
        "        print(\"dz3 shape\")\n",
        "        # Compute gradients for W3 and b3\n",
        "        dW3 = np.dot(self.a2.T, dz3)  # (hidden_size2, o)\n",
        "        db3 = np.sum(dz3, axis=0, keepdims=True)  # (1, o)\n",
        "\n",
        "        # Hidden Layer Propagate the error back to Hidden Layer 2\n",
        "        dz2 = np.dot(dz3, self.W3.T) * self.sigmoid_derivative(self.a2)  # (m, h2)\n",
        "\n",
        "        # Compute gradients for W2 and b2\n",
        "        dW2 = np.dot(self.a1.T, dz2)  # (hidden_size1, hidden_size2)\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True)  # (1, h2)\n",
        "\n",
        "\n",
        "        # Hidden Layer 1.. Propagate the error back to Hidden Layer 1\n",
        "        dz1 = np.dot(dz2, self.W2.T) * self.sigmoid_derivative(self.a1)  # (m, h1)\n",
        "\n",
        "        # Compute gradients for W1 and b1\n",
        "        dW1 = np.dot(X.T, dz1)  # (input_size, h1)\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True)  # (1, h1)\n",
        "\n",
        "\n",
        "        # Update Weights and Biases\n",
        "\n",
        "        self.W3 -= self.learning_rate * dW3\n",
        "        self.b3 -= self.learning_rate * db3\n",
        "        self.W2 -= self.learning_rate * dW2\n",
        "        self.b2 -= self.learning_rate * db2\n",
        "        self.W1 -= self.learning_rate * dW1\n",
        "        self.b1 -= self.learning_rate * db1\n",
        "\n",
        "    def train(self, X, y, epochs, learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "        for epoch in range(epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            loss = self.compute_loss(y, y_pred)\n",
        "            self.backward(X, y, y_pred)\n",
        "            if epoch % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = self.forward(X)\n",
        "        return (y_pred > 0.5).astype(int)\n",
        "\n",
        "    def accuracy(self, y_true, y_pred):\n",
        "        return np.mean(np.round(y_pred) == y_true)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from NN import NN\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('heart.csv')\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert y_train and y_test to NumPy arrays before reshaping\n",
        "y_train = y_train.values.reshape(-1, 1)\n",
        "y_test = y_test.values.reshape(-1, 1)\n",
        "\n",
        "nn = NN(13, 10, 1)\n",
        "nn.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
        "y_pred = nn.predict(X_test.values)\n",
        "accuracy = nn.accuracy(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3rm6_nvgcYH",
        "outputId": "87f17a12-bca1-4ec3-9efa-928e951d7b4b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.48183460531515443\n",
            "Epoch 100, Loss: 0.481776057496921\n",
            "Epoch 200, Loss: 0.48171448398825356\n",
            "Epoch 300, Loss: 0.4816496449431339\n",
            "Epoch 400, Loss: 0.48158127455589733\n",
            "Epoch 500, Loss: 0.4815090774605677\n",
            "Epoch 600, Loss: 0.48143272451517083\n",
            "Epoch 700, Loss: 0.481351847845137\n",
            "Epoch 800, Loss: 0.4812660349896141\n",
            "Epoch 900, Loss: 0.4811748219558116\n",
            "Accuracy: 0.5024390243902439\n"
          ]
        }
      ]
    }
  ]
}